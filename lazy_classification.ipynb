{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - 2\n",
    "For solving task 1 and 2 we will define function for lazy FCA classification. This function will use compute intersect computation function for getting intersect between row in dataset and row we want to classify. And function for computing extent base on intersect computed from previos function. Also we add function for computing intervals as argument with default value for future tasks 4 and 5. We also can set verbose to 1 for logging every step of classifier. Also we define function for computing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_itersect(data_row, classification_row, interval_constructor=None):\n",
    "    \"\"\"\n",
    "    This func compute intersection between two given rows.\n",
    "\n",
    "    Arguments:\n",
    "        data_row (list) -- data row\n",
    "        classification_row (list) -- row that we try to classify\n",
    "        interval_constructor (method) -- method for computing interval (default None)\n",
    "\n",
    "    Return: \n",
    "        intersection (np.array) -- array with computed intersaction that \n",
    "            can be used as pattern for filtering data \n",
    "    \"\"\"\n",
    "    intersection = []\n",
    "\n",
    "    if len(data_row) - len(classification_row) != 1 and len(data_row) != len(classification_row):\n",
    "        raise Exception\n",
    "\n",
    "    for i in range(len(classification_row)):\n",
    "        if type(classification_row[i]) is str:\n",
    "            if data_row[i] != classification_row[i]:\n",
    "                intersection.append('*')\n",
    "            else:\n",
    "                intersection.append(classification_row[i])\n",
    "        else:\n",
    "            if interval_constructor is None:\n",
    "                intersection.append((min(data_row[i], classification_row[i]), max(data_row[i], classification_row[i])))\n",
    "            else:\n",
    "                intersection.append(interval_constructor(data_row[i], classification_row[i]))\n",
    "\n",
    "    return np.array(intersection, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_extent(data, pattern):\n",
    "    \"\"\"\n",
    "    This func compute extent for pattern and data.\n",
    "    Arguments:\n",
    "        data (pandas.DataFrame) -- data frame with train data\n",
    "        pattern (np.array) -- pattern for filtering rows\n",
    "\n",
    "    Return: \n",
    "        extent (list) -- list with tuples, where first value is row index and second value is target value for extent\n",
    "    \"\"\"\n",
    "    extent = []\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return extent\n",
    "\n",
    "    if data.shape[1] - pattern.shape[0] != 1 and data.shape[1] != pattern.shape[0]:\n",
    "        raise Exception \n",
    "\n",
    "    for row_index in range(data.shape[0]):\n",
    "        row = data.iloc[row_index]\n",
    "        is_fit = True\n",
    "        for i in range(len(pattern)):\n",
    "            if type(row[i]) is str:\n",
    "                if pattern[i] != '*' and row[i] != pattern[i]:\n",
    "                    is_fit = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[i] < pattern[i][0] or row[i] > pattern[i][1]:\n",
    "                    is_fit = False\n",
    "                    break\n",
    "        \n",
    "        if is_fit:\n",
    "            extent.append((row_index, row[-1]))\n",
    "\n",
    "    return extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificator(train, test, verbose=0, interval_constructor=None):\n",
    "    \"\"\"\n",
    "    Lazy FCA classificator.\n",
    "    Arguments:\n",
    "        train (pandas.DataFrame) -- data frame with train data\n",
    "        test (pandas.DataFrame) -- data frame with data fro classification\n",
    "        verbose (int) -- value for controling logging, if 0 won't log anything otherwise print computation steps\n",
    "        interval_constructor (method) -- method for computing interval (default None)\n",
    "    Return: \n",
    "        answers (list) -- return classification results, if object can't be classified put U (Undefined) in list\n",
    "    \"\"\"\n",
    "    answers = []\n",
    "    for test_row in test.iloc:\n",
    "        is_classified = False\n",
    "        for train_row in train.iloc:\n",
    "            pattern = compute_itersect(train_row.to_list(), test_row.to_list(), interval_constructor=interval_constructor)\n",
    "            extent = compute_extent(train, pattern)\n",
    "            if verbose:\n",
    "                print(pattern)\n",
    "                print(extent)\n",
    "            if len(extent) != 0 and all(extent[0][1] == x[1] for x in extent):\n",
    "                answers.append(extent[0][1])\n",
    "                is_classified = True\n",
    "                break\n",
    "        if not is_classified:\n",
    "            answers.append('U')\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(predictions, answers):\n",
    "    \"\"\"Count accuracy for prediction and correct answers\n",
    "    Arguments:\n",
    "        predictions (list) -- labels that was predicted\n",
    "        answers (list) -- write predictions\n",
    "    Return: \n",
    "        accuracy (float) -- accuracy for giving data\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(answers) != len(predictions):\n",
    "        raise Exception\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if answers.iloc[i] == predictions[i]:\n",
    "            count += 1\n",
    "    \n",
    "    return count / len(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 8),\n",
       "    System   mount  price  CON  SnOW  ice dur  dur Accegrade\n",
       " 0      SK       F    206  1.9   1.4      1.8  2.7         F\n",
       " 1     SRK  F or R    520  2.1   0.8      3.8  2.3         F\n",
       " 2      SK       F    160  1.7   1.9      1.6  3.7         F\n",
       " 3      SK       F    213  1.7   2.0      2.4  3.4         F\n",
       " 4     SMS  F or R    598  1.6   2.4      2.7  2.8         F\n",
       " 5      SK       F    109  2.0   1.9      2.4  3.7         F\n",
       " 6     SRK  F or R    325  2.0   2.1      3.2  2.8         T\n",
       " 7     SMS  F or R    498  1.5   3.3      3.5  2.0         T\n",
       " 8     SRK  F or R    396  2.8   2.1      3.1  2.5         T\n",
       " 9     SRK  F or R    325  2.2   2.2      4.6  3.2         T\n",
       " 10    SRK  F or R    389  2.0   2.2      3.3  4.3         T\n",
       " 11    SRK       F    298  2.5   2.3      3.3  2.8         T\n",
       " 12     SK       F    149  1.9   2.5      4.0  3.8         T\n",
       " 13    SMS  F or R    684  1.7   3.3      4.4  2.2         T\n",
       " 14     SK       F     99  2.8   2.2      2.5  4.0         T\n",
       " 15     SK       F    140  2.6   2.3      3.3  3.4         T\n",
       " 16     SK       F    215  2.3   3.8      4.8  2.3         T)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Wheel_Chains_Dataset.csv\", sep=';')\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, 206) (1.9, 2.8) (1.4, 2.2) (1.8, 2.5) (2.7, 4.0)]\n",
      "[(0, 'F'), (5, 'F')]\n",
      "['SK' 'F' (140, 206) (1.9, 2.6) (1.4, 2.3) (1.8, 3.3) (2.7, 3.4)]\n",
      "[(0, 'F')]\n",
      "['SK' 'F' (206, 215) (1.9, 2.3) (1.4, 3.8) (1.8, 4.8) (2.3, 2.7)]\n",
      "[(0, 'F')]\n",
      "['F', 'F', 'F']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.iloc[:-3]\n",
    "test = data.iloc[-3:].drop(columns=[\"Accegrade\"])\n",
    "test_y = data.iloc[-3:][\"Accegrade\"]\n",
    "prediction = classificator(train, test, verbose=1)\n",
    "print(prediction)\n",
    "count_accuracy(prediction, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for results\n",
    "Here we have very poor accuracy. In my opinion, this is because we have only one object in most of our extents, so we have to change our algorithm a bit, such as taking the average prediction instead of just the first one, or changing the function for calculating the intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 8),\n",
       "    System   mount  price  CON  SnOW  ice dur  dur Accegrade\n",
       " 0      SK       F    149  1.9   2.5      4.0  3.8         T\n",
       " 1     SRK  F or R    520  2.1   0.8      3.8  2.3         F\n",
       " 2     SRK  F or R    389  2.0   2.2      3.3  4.3         T\n",
       " 3      SK       F    213  1.7   2.0      2.4  3.4         F\n",
       " 4     SMS  F or R    598  1.6   2.4      2.7  2.8         F\n",
       " 5      SK       F    109  2.0   1.9      2.4  3.7         F\n",
       " 6     SRK  F or R    325  2.0   2.1      3.2  2.8         T\n",
       " 7     SMS  F or R    498  1.5   3.3      3.5  2.0         T\n",
       " 8     SRK  F or R    396  2.8   2.1      3.1  2.5         T\n",
       " 9      SK       F    160  1.7   1.9      1.6  3.7         F\n",
       " 10    SRK  F or R    389  2.0   2.2      3.3  4.3         T\n",
       " 11    SRK       F    298  2.5   2.3      3.3  2.8         T\n",
       " 12     SK       F    206  1.9   1.4      1.8  2.7         F\n",
       " 13    SMS  F or R    684  1.7   3.3      4.4  2.2         T\n",
       " 14     SK       F     99  2.8   2.2      2.5  4.0         T\n",
       " 15     SK       F    140  2.6   2.3      3.3  3.4         T\n",
       " 16     SK       F    215  2.3   3.8      4.8  2.3         T)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Wheel_Chains_Dataset_difforder.csv\", sep=';')\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, 149) (1.9, 2.8) (2.2, 2.5) (2.5, 4.0) (3.8, 4.0)]\n",
      "[(0, 'T')]\n",
      "['SK' 'F' (140, 149) (1.9, 2.6) (2.3, 2.5) (3.3, 4.0) (3.4, 3.8)]\n",
      "[(0, 'T')]\n",
      "['SK' 'F' (149, 215) (1.9, 2.3) (2.5, 3.8) (4.0, 4.8) (2.3, 3.8)]\n",
      "[(0, 'T')]\n",
      "['T', 'T', 'T']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.iloc[:-3]\n",
    "test = data.iloc[-3:].drop(columns=[\"Accegrade\"])\n",
    "test_y = data.iloc[-3:][\"Accegrade\"]\n",
    "prediction = classificator(train, test, verbose=1)\n",
    "print(prediction)\n",
    "count_accuracy(prediction, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for results\n",
    "Here we have too good acuracy to be true. We just lucky becouse changing order of dataset help us with getting right results. For getting correct accuracy we should use cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "Here we use cross validation with 6 folds for computing appropriate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, folds=5, verbose=0, interval_constructor=None):\n",
    "    \"\"\"\n",
    "    Cross validation for counting Lazy FCA classifier avarage accuracy.\n",
    "    Arguments:\n",
    "        data (pandas.DataFrame) -- data frame with data for counting avarage accuracy\n",
    "        folds (int) -- number of folds for cross validation\n",
    "        verbose (int) -- value for controling logging, if 0 won't log anything otherwise print computation steps\n",
    "        interval_constructor (method) -- method for computing interval (default None)\n",
    "    Return: \n",
    "        avarage accuracy (float) -- return avarage accuracy for all folds\n",
    "    \"\"\"\n",
    "    accuracys = np.array([])\n",
    "    fold_size = int(np.ceil(data.shape[0] / folds))\n",
    "    for i in range(0, data.shape[0], fold_size):\n",
    "        train = pd.concat([data.iloc[: i], data.iloc[i + fold_size:]])\n",
    "        test = data.iloc[i : i + fold_size].drop(columns=[\"Accegrade\"])\n",
    "        test_y = data.iloc[i : i + fold_size][\"Accegrade\"]\n",
    "        if verbose:\n",
    "            print(f\"Fold {i // fold_size + 1}\")\n",
    "        prediction = classificator(train, test, verbose=verbose, interval_constructor=interval_constructor)\n",
    "        accuracy = count_accuracy(prediction, test_y)\n",
    "        accuracys = np.append(accuracys, accuracy)\n",
    "        if verbose:\n",
    "            print(\"Accuracy for fold %d is %.2f \\n\"%(i // fold_size + 1, accuracy))\n",
    "\n",
    "    return np.average(accuracys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "['SK' 'F' (149, 213) (1.7, 1.9) (2.0, 2.5) (2.4, 4.0) (3.4, 3.8)]\n",
      "[(0, 'F')]\n",
      "['*' '*' (213, 520) (1.7, 2.1) (0.8, 2.0) (2.4, 3.8) (2.3, 3.4)]\n",
      "[(0, 'F')]\n",
      "['*' '*' (213, 389) (1.7, 2.0) (2.0, 2.2) (2.4, 3.3) (3.4, 4.3)]\n",
      "[(0, 'F'), (7, 'T')]\n",
      "['*' 'F or R' (389, 598) (1.6, 2.0) (2.2, 2.4) (2.7, 3.3) (2.8, 4.3)]\n",
      "[(1, 'F'), (7, 'T')]\n",
      "['*' '*' (109, 389) (2.0, 2.0) (1.9, 2.2) (2.4, 3.3) (3.7, 4.3)]\n",
      "[(2, 'F'), (7, 'T')]\n",
      "['SRK' 'F or R' (325, 389) (2.0, 2.0) (2.1, 2.2) (3.2, 3.3) (2.8, 4.3)]\n",
      "[(3, 'T'), (7, 'T')]\n",
      "Accuracy for fold 1 is 0.67 \n",
      "\n",
      "Fold 2\n",
      "['SK' 'F' (149, 213) (1.7, 1.9) (2.0, 2.5) (2.4, 4.0) (3.4, 3.8)]\n",
      "[(0, 'T')]\n",
      "['*' '*' (149, 598) (1.6, 1.9) (2.4, 2.5) (2.7, 4.0) (2.8, 3.8)]\n",
      "[(0, 'T')]\n",
      "['SK' 'F' (109, 149) (1.9, 2.0) (1.9, 2.5) (2.4, 4.0) (3.7, 3.8)]\n",
      "[(0, 'T')]\n",
      "Accuracy for fold 2 is 0.00 \n",
      "\n",
      "Fold 3\n",
      "['*' '*' (149, 325) (1.9, 2.0) (2.1, 2.5) (3.2, 4.0) (2.8, 3.8)]\n",
      "[(0, 'T')]\n",
      "['*' '*' (149, 498) (1.5, 1.9) (2.5, 3.3) (3.5, 4.0) (2.0, 3.8)]\n",
      "[(0, 'T')]\n",
      "['*' '*' (149, 396) (1.9, 2.8) (2.1, 2.5) (3.1, 4.0) (2.5, 3.8)]\n",
      "[(0, 'T'), (8, 'T')]\n",
      "Accuracy for fold 3 is 1.00 \n",
      "\n",
      "Fold 4\n",
      "['SK' 'F' (149, 160) (1.7, 1.9) (1.9, 2.5) (1.6, 4.0) (3.7, 3.8)]\n",
      "[(0, 'T')]\n",
      "['*' '*' (149, 389) (1.9, 2.0) (2.2, 2.5) (3.3, 4.0) (3.8, 4.3)]\n",
      "[(0, 'T'), (2, 'T')]\n",
      "['*' 'F' (149, 298) (1.9, 2.5) (2.3, 2.5) (3.3, 4.0) (2.8, 3.8)]\n",
      "[(0, 'T')]\n",
      "Accuracy for fold 4 is 0.67 \n",
      "\n",
      "Fold 5\n",
      "['SK' 'F' (149, 206) (1.9, 1.9) (1.4, 2.5) (1.8, 4.0) (2.7, 3.8)]\n",
      "[(0, 'T')]\n",
      "['*' '*' (149, 684) (1.7, 1.9) (2.5, 3.3) (4.0, 4.4) (2.2, 3.8)]\n",
      "[(0, 'T')]\n",
      "['SK' 'F' (99, 149) (1.9, 2.8) (2.2, 2.5) (2.5, 4.0) (3.8, 4.0)]\n",
      "[(0, 'T')]\n",
      "Accuracy for fold 5 is 0.67 \n",
      "\n",
      "Fold 6\n",
      "['SK' 'F' (140, 149) (1.9, 2.6) (2.3, 2.5) (3.3, 4.0) (3.4, 3.8)]\n",
      "[(0, 'T')]\n",
      "['SK' 'F' (149, 215) (1.9, 2.3) (2.5, 3.8) (4.0, 4.8) (2.3, 3.8)]\n",
      "[(0, 'T')]\n",
      "Accuracy for fold 6 is 1.00 \n",
      "\n",
      "Cross validation accuracy 66.67%\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross validation accuracy %.2f\"%(cross_validation(data, folds=6, verbose=1) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "Here we define new function for computing intervals and try it with object number 15. It looks like better method, but let's try cross validation for appropriate check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_inf_interval(a_1, a_2):\n",
    "    return (min(a_1, a_2), float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, inf) (1.9, inf) (2.2, inf) (2.5, inf) (3.8, inf)]\n",
      "[(0, 'T')]\n",
      "['T']\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([data.iloc[:14], data.iloc[15:]])\n",
    "test = data.iloc[14:15].drop(columns=[\"Accegrade\"])\n",
    "test_y = data.iloc[14:15][\"Accegrade\"]\n",
    "prediction = classificator(train, test, verbose=1, interval_constructor=min_inf_interval)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracy 66.67%\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross validation accuracy %.2f\"%(cross_validation(data, folds=6, verbose=0, interval_constructor=min_inf_interval) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "Another function for tring with object 15. It looks like worth method, but let's try cross validation for appropriate check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_inf_interval(a_1, a_2):\n",
    "    return (max(a_1, a_2), float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (149, inf) (2.8, inf) (2.5, inf) (4.0, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (520, inf) (2.8, inf) (2.2, inf) (3.8, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (389, inf) (2.8, inf) (2.2, inf) (3.3, inf) (4.3, inf)]\n",
      "[]\n",
      "['SK' 'F' (213, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (598, inf) (2.8, inf) (2.4, inf) (2.7, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (109, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (325, inf) (2.8, inf) (2.2, inf) (3.2, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (498, inf) (2.8, inf) (3.3, inf) (3.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (396, inf) (2.8, inf) (2.2, inf) (3.1, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (160, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (389, inf) (2.8, inf) (2.2, inf) (3.3, inf) (4.3, inf)]\n",
      "[]\n",
      "['*' 'F' (298, inf) (2.8, inf) (2.3, inf) (3.3, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (206, inf) (2.8, inf) (2.2, inf) (2.5, inf) (4.0, inf)]\n",
      "[]\n",
      "['*' '*' (684, inf) (2.8, inf) (3.3, inf) (4.4, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (140, inf) (2.8, inf) (2.3, inf) (3.3, inf) (4.0, inf)]\n",
      "[]\n",
      "['SK' 'F' (215, inf) (2.8, inf) (3.8, inf) (4.8, inf) (4.0, inf)]\n",
      "[]\n",
      "['U']\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([data.iloc[:14], data.iloc[15:]])\n",
    "test = data.iloc[14:15].drop(columns=[\"Accegrade\"])\n",
    "test_y = data.iloc[14:15][\"Accegrade\"]\n",
    "prediction = classificator(train, test, verbose=1, interval_constructor=max_inf_interval)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracy 22.22%\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross validation accuracy %.2f\"%(cross_validation(data, folds=6, verbose=0, interval_constructor=max_inf_interval) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments for results\n",
    "\n",
    "We have tried two different methods for computing intervals. I think that first method is more appropriate for our dataset, because second one is too strickt and objects usually get undefined tag. Same results show cross validation. Max inf interval get lower accuracy then min inf. However both methods give low accuracy, so actually we should better try other approaches for tunning our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1df68fc9fa01dac7be281f8dd0d32217a1f401dffd563477ddf5abfb5bb3b20b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_itersect(data_row, classification_row):\n",
    "    \"\"\"\n",
    "    This func compute intersection between two given rows\n",
    "    \"\"\"\n",
    "    intersection = []\n",
    "\n",
    "    if len(data_row) - len(classification_row) != 1 and len(data_row) != len(classification_row):\n",
    "        raise Exception\n",
    "\n",
    "    for i in range(len(classification_row)):\n",
    "        if type(classification_row[i]) is str:\n",
    "            if data_row[i] != classification_row[i]:\n",
    "                intersection.append('*')\n",
    "            else:\n",
    "                intersection.append(classification_row[i])\n",
    "        else:\n",
    "            intersection.append((min(data_row[i], classification_row[i]), max(data_row[i], classification_row[i])))\n",
    "\n",
    "    return np.array(intersection, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_extent(data, pattern):\n",
    "    \"\"\"\n",
    "    This func compute extent for pattern and data\n",
    "    \"\"\"\n",
    "    extent = []\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return extent\n",
    "\n",
    "    if data.shape[1] - pattern.shape[0] != 1 and data.shape[1] != pattern.shape[0]:\n",
    "        raise Exception \n",
    "\n",
    "    for row_index in range(data.shape[0]):\n",
    "        row = data.iloc[row_index]\n",
    "        is_fit = True\n",
    "        for i in range(len(pattern)):\n",
    "            if type(row[i]) is str:\n",
    "                if pattern[i] != '*' and row[i] != pattern[i]:\n",
    "                    is_fit = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[i] < pattern[i][0] or row[i] > pattern[i][1]:\n",
    "                    is_fit = False\n",
    "                    break\n",
    "        \n",
    "        if is_fit:\n",
    "            extent.append((row_index, row[-1]))\n",
    "\n",
    "    return extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificator(train, test, verbose=0):\n",
    "    answers = []\n",
    "    for test_row in test.iloc:\n",
    "        is_classified = False\n",
    "        for train_row in train.iloc:\n",
    "            pattern = compute_itersect(train_row.to_list(), test_row.to_list())\n",
    "            extent = compute_extent(train, pattern)\n",
    "            if verbose:\n",
    "                print(pattern)\n",
    "                print(extent)\n",
    "            if all(extent[0][1] == x[1] for x in extent):\n",
    "                answers.append(extent[0][1])\n",
    "                is_classified = True\n",
    "                break\n",
    "        if not is_classified:\n",
    "            answers.append('U')\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accourac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Wheel_Chains_Dataset.csv\", sep=';')\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, 206) (1.9, 2.8) (1.4, 2.2) (1.8, 2.5) (2.7, 4.0)]\n",
      "[(0, 'F'), (5, 'F')]\n",
      "['SK' 'F' (140, 206) (1.9, 2.6) (1.4, 2.3) (1.8, 3.3) (2.7, 3.4)]\n",
      "[(0, 'F')]\n",
      "['SK' 'F' (206, 215) (1.9, 2.3) (1.4, 3.8) (1.8, 4.8) (2.3, 2.7)]\n",
      "[(0, 'F')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['F', 'F', 'F']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.iloc[:-3]\n",
    "test = data.iloc[-3:].drop(columns=[\"Accegrade\"])\n",
    "test_y = data.iloc[-3:][\"Accegrade\"]\n",
    "classificator(train, test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 8),\n",
       "    System   mount  price  CON  SnOW  ice dur  dur Accegrade\n",
       " 0      SK       F    149  1.9   2.5      4.0  3.8         T\n",
       " 1     SRK  F or R    520  2.1   0.8      3.8  2.3         F\n",
       " 2     SRK  F or R    389  2.0   2.2      3.3  4.3         T\n",
       " 3      SK       F    213  1.7   2.0      2.4  3.4         F\n",
       " 4     SMS  F or R    598  1.6   2.4      2.7  2.8         F\n",
       " 5      SK       F    109  2.0   1.9      2.4  3.7         F\n",
       " 6     SRK  F or R    325  2.0   2.1      3.2  2.8         T\n",
       " 7     SMS  F or R    498  1.5   3.3      3.5  2.0         T\n",
       " 8     SRK  F or R    396  2.8   2.1      3.1  2.5         T\n",
       " 9      SK       F    160  1.7   1.9      1.6  3.7         F\n",
       " 10    SRK  F or R    389  2.0   2.2      3.3  4.3         T\n",
       " 11    SRK       F    298  2.5   2.3      3.3  2.8         T\n",
       " 12     SK       F    206  1.9   1.4      1.8  2.7         F\n",
       " 13    SMS  F or R    684  1.7   3.3      4.4  2.2         T\n",
       " 14     SK       F     99  2.8   2.2      2.5  4.0         T\n",
       " 15     SK       F    140  2.6   2.3      3.3  3.4         T\n",
       " 16     SK       F    215  2.3   3.8      4.8  2.3         T)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Wheel_Chains_Dataset_difforder.csv\", sep=';')\n",
    "data.shape, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK' 'F' (99, 149) (1.9, 2.8) (2.2, 2.5) (2.5, 4.0) (3.8, 4.0)]\n",
      "[(0, 'T')]\n",
      "['SK' 'F' (140, 149) (1.9, 2.6) (2.3, 2.5) (3.3, 4.0) (3.4, 3.8)]\n",
      "[(0, 'T')]\n",
      "['SK' 'F' (149, 215) (1.9, 2.3) (2.5, 3.8) (4.0, 4.8) (2.3, 3.8)]\n",
      "[(0, 'T')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['T', 'T', 'T']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.iloc[:-3]\n",
    "test = data.iloc[-3:].drop(columns=[\"Accegrade\"])\n",
    "test_y = data.iloc[-3:][\"Accegrade\"]\n",
    "classificator(train, test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1df68fc9fa01dac7be281f8dd0d32217a1f401dffd563477ddf5abfb5bb3b20b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
